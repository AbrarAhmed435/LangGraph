{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f972ffdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, START,END\n",
    "from typing import TypedDict\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from dotenv import load_dotenv\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "load_dotenv()\n",
    "\n",
    "# model=ChatGoogleGenerativeAI(model='gemini-2.5-flash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec09c3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n",
    "llm=HuggingFaceEndpoint(\n",
    "    # repo_id=\"HuggingFaceH4/zephyr-7b-beta\",\n",
    "    repo_id=\"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "    # repo_id=\"HuggingFaceH4/zephyr-7b-gemma-v0.1\",\n",
    "    # repo_id=\"lmsys/vicuna-13b-v1.5\",\n",
    "    task=\"text-generation\"\n",
    ")\n",
    "model=ChatHuggingFace(llm=llm)\n",
    "# generator=ChatHuggingFace(llm=llm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "079db000",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JokeState(TypedDict):\n",
    "    topic:str\n",
    "    joke:str\n",
    "    explanation:str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35ef1aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_joke(state:JokeState):\n",
    "    response=model.invoke(f\"Generate a joke on topic:{state['topic']}\")\n",
    "    return {\n",
    "        'joke':response.content\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2cfe270a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_explanation(state:JokeState):\n",
    "    response=model.invoke(f\"Explain this joke , Joke:{state['joke']}\")\n",
    "\n",
    "    return {\n",
    "        'explanation':response.content\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a5e88ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph=StateGraph(JokeState)\n",
    "\n",
    "graph.add_node('generate_joke',generate_joke)\n",
    "graph.add_node('generate_explanation',generate_explanation)\n",
    "\n",
    "graph.add_edge(START,'generate_joke')\n",
    "graph.add_edge('generate_joke','generate_explanation')\n",
    "graph.add_edge('generate_explanation',END)\n",
    "\n",
    "checkpointer=InMemorySaver()\n",
    "\n",
    "workflow=graph.compile(checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a9b9c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOOGLE_API_KEY: AIzaSyAi7N-5CPgBw9xg9MORoCMQ5p2tSB-XTuQ\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"GOOGLE_API_KEY:\", os.getenv(\"GOOGLE_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e12224fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Hello! How can I help you today? If you have any questions or topics you'd like to discuss, feel free to ask. I'm here to provide information and answer any queries you may have. Let me know if you have something specific in mind, or if you just want to chat about a particular topic. I'm here for you!\\n\\nIf you're looking for general conversation, we could talk about a wide range of topics such as science, technology, art, literature, music, movies, sports, or current events. Let me know what you're interested in and we can go from there. Alternatively, if you have a specific question, I'll do my best to provide you with accurate and reliable information.\\n\\nSo, what would you like to discuss today? I'm all ears!\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"hello\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f22b01b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "config1={\"configurable\":{\"thread_id\":'1'}}\n",
    "\n",
    "# workflow.invoke({'topic':'pizza'},config=config1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "34b3fb09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={}, next=(), config={'configurable': {'thread_id': '1'}}, metadata=None, created_at=None, parent_config=None, tasks=(), interrupts=())"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.get_state(config1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49083df2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{}, (), {'configurable': {'thread_id': '1'}}, None, None, None, (), ()]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(workflow.get_state(config1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9bd42613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(workflow.get_state(config1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_langgraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
